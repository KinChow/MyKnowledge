# arm软件性能优化

## 基础知识

### 芯片知识

* CCL：CPU cluster，一个CCL有多个CPU core。
* SCCL：Super CPU cluster，也称Die，一个SCCL有多个CCL。
* Chip：也称socket，一个chip内有2多个SCCL，多个chip之间通过Hydra接口连接。



CPU访问不同存储，序号越大，访问时延越大，下面是一些参考值

* L1 latency: 4 cycle
* L2 Latency: 8 cycle
* L3 latency: 38 cycle
* DDR local latency: 88ns
* DDR cross die: 105ns
* DDR remote latency: 192~230ns



### cpu存储层次



### 流水线

#### Execution Throughput

芯片手册里面的Execution Throughput被定义为最大吞吐（instructions/cycle），也就是说一个CPU cycle内所能执行的最多指令条数；比如这里执行吞吐为2，表达的意思就是说：你的代码写的再好，也最多平均一个CPU cycle跑2条CLS/CLZ/CNT指令。

* Exec Latency：指令执行所需要的时间
* Utilized Pipelines：执行该指令的流水线

这种一个cycle能执行2条或更多的指令，一般在硬件上通过复制流水线结构实现，让复制的流水线并行执行，这种叫做超标量流水线。



#### 冲突

软件优化的目的是要让流水线保持最大的吞吐率，流水尽量不被打断（比如中断、cache miss、TLB miss）。流水线由于硬件资源有限，会发生冲突（hazard），影响流水线的效率。冲突主要有以下几种：

* 结构冲突（Structural hazard）
    * 当两个或多个指令同时需要处理器硬件的一部分时，就会发生结构危险。比如争抢LD/ST单元。
* 数据冲突（Data hazard）
    * 当指令在流水线中重叠执行时，因需要用到前面指令的执行结果而发生的冲突。
        * read after write (RAW), a true dependency
        * write after read (WAR), an anti-dependency
        * write after write (WAW), an output dependency
*   控制冲突（Control hazard）
    * 流水线遇到分支指令或其它会改变PC值的指令所引起的冲突。
    数据冲突影响到的仅仅是本条指令附近少数几条指令，所以称为局部冲突。而控制沖突影响的范围要大得多，它会引起程序执行万向的改变，使流水线损失更多的性能，所以称为全局冲突。
    在进行汇编级的优化时，主要是针对这几种冲突来进行流水线的优化。



### 向量指令集



### NUMA

从2006年左右开始，所有的PC、服务器的处理器，都迈入了多核时代。这时出现了第一代多核架构，称为SMP：也就是对称多处理器架构。在SMP架构下的计算机中，每个核都是对等的，所有的核通过总线访问所有内存，每个进程在调度时，可以在任意一个核上运行，在操作系统和內核的支持下，整个系統能做到非常好的负載均衡，性能得到很好的发挥。
但是，我们也看到了一个问题。所有的核均通过总线访问内存，且共用一个控制器，当核数不断增加的时候，内存总线和单一控制器成为了内存访问的瓶颈。为了解决这一问题，NUMA架构出现了。
NUMA架构也叫非统一的内存访问架构（Non-uniform memory access），下图是一个NUMA架构的示例，这里有两个CPU，在NUMA架构下，CPU被分成了多个节点Node。每个节点有自己的內存Controller，也有自己的内存插槽，这个内存的访问不再受一条内存总线带宽的限制。NUMA node之间的内存访问，通过片内的和片间的高速总线完成。



### PMU

在ARM CPU里包含有Performance Monitor Unit（PMU），可以用来对CPU内部发生的一些事件进行计数，通过与软件的配合，就可以实现在程序运行过程中，对CPU的一些行为进行统计，从而可以分析程序在该CPU上的执行情况。

所能统计的CPU事件是由CPU实现来决定的，并且用事件编号来区分不同的事件。可以参考对应型号CPU的手册来查找。

不同的CPU除了实现ARM架构定义的事件外，可能还会实现专有的事件。

我们常用的应用程序性能分析工具perf就是通过读取CPU内部的PMU统计事件来进行性能分析的。





## 性能优化的维度

### 软件

性能优化涉及软件的方方面面，需要做端到端的深入分析，在各个环节最大程度地挖掘性能瓶颈，并保证各个环节的优化不会相互冲突，出现1+1<2的情况。自顶向下，可以把软件性能优化分为以下几个层次：业务级、系统架构，算法、代码级、编译器。

* 业务级的层次最高，通过对业务场景中的软硬件资源合理配置来实现负载均衡及性能优化，比如大数据场景通过增加计算资源或优化储存来优化业务性能
* 系统架构级的优化也是比校有效的优化手段，模块划分及交互、数据流、约束等这都是这一层级要考虑的问题
* 算法级的优化主要是针对某一场景或具体问题的优化，需要综合考虑算法时间复杂度及空间复杂度
* 代码级的优化指通过一些编程技巧，对代码（包括高级语言及汇编语言）做出符合硬件运行规律的优化
* 编译器的优化包括编译器本身对代码的自动优化，也包括程序员通过编译选顶指导编译器进行优化。
后面三个层次的优化不但针对普通的应用程序，也包括操作系统等软件。



### 硬件

所有的软件手段本质上，从硬件角度上不外乎内存读写优化、cache命中率优化、流水线优化、计算能力最大化（对于单核：向量指令集、原子指令，对于多核：并行化）。

* 内存读写优化：通过选择合适的软件算法或编码技巧来减少内存读写的数量，或减少内存读写的延迟，比如在某些场景使用大页表来或减小热点数据大小来降低TLB miss率，减少TLB walk带来的内存访问延迟（注意大页表容易带来内存使用效率降低）。另外一个例子是通过调整结构体的字节对齐方式提总线读写效率，最终降低访存延迟。
* cache命中率优化：cache命中率对软件性能影响巨大，一直是性能优化的重中之重。主要是通过调整数据排列方式使热点数据尽量不被替换出去。如消除伪共享、数据重排等。
* 流水线优化：这里的指严格意义上的通过调整指令顺序/替换指令等操作来解决流水线冲突，实现执行效率最大化（实际上通过优化cache命中率使cpu尽量不去访内存也是一种流水线优化）。
* 计算能力最大化：通过使用性能更高的指令来发挥硬件最大性能，如向量化指令、使用原子锁代替Load-Exclusive/Store-Exclusive指令等，或者优化表达式来减少运算量。





## 性能优化方法

### 发现性能瓶颈

要进行性能优化，首先需要各种分析找到性能瓶颈，主要依靠代码检视、perf等工具。



### 工具

* perf
    * https://perf.wiki.kernel.org/index.php/Tutorial
    * http://zhuanlan.zhihu.com/p/22194920
* ftrace
    * 主要用于记录内核函数运行轨迹。基本使用方法：
        * `trace-cmd record -p function_graph-P 25314`
        * `trace-cmd report > trace.data`
* strace
    * 跟踪系统调用。基本使用方法
        * `strace -c -p pid`：查看系统调用统计
        * `strace -p pid`：查看系统调用执行过程
        * `strace -T -p pid`：查看系统调用执行过程，并加上时间
* ltrace
    * 跟踪进程的库函数调用，它会显现出哪个库函数被调用。
* top



### 一些例子

* 定位锁的问题
    * 大家都知道锁会引入额外开销，但锁的开销到底有多大，估计很多人没有实测过，我可以给一个数据，一般单次加解锁100 cycles，spinlock或者cas更快一点。
    * 使用锁的时候，要注意锁的粒度，但锁的粒度也不是越小越好，太大会增加撞锁的概率，太小会导致代码更难写。
    * 多线程场景下，如果cpu利用率上不去，而系统吞吐也上不去，那就有可能是锁导致的性能下降，这个时候，可以观落序的sys cpu/usr cpu （cpu在内核态/用户态的运行时间），这个时候通过perf如果发现lock的开销大，那就没错了。
    * 如果程序卡住了，可以用pstack把堆栈打出来，定位死锁的问题。
* D-Cache优化技术洞察和探索
* 利用Cachegrind帮助优化D-Cache命中率





## 性能调优方法

### 算法优化

算法层面的优化相比底层的代码优化往往能带来更大的收益，对于包含较多算法的软件，首先应该考虑算法的优化。最简单的例子，在序列基本有序的情况下，选择冒泡排序会比快速排序更有效一些。



### 编译选项

#### 自动向量化

根据指令支持情况，将循环、多条相似的简单语句等优化为SIMD指令的编译器特性。GCC编译器在2008年版本开始加入了，并且在-O3优化模式下默认打开自动向量化优化的开关。使用方法：
* 编译选项中填写-free-vectorize，或编译优化设置为-O3（一般不推荐）
* 可添加-ftree-vectorizer-verbose进行编译时优化的查看。



#### 编译优化级别

GCC为了满足用户不同程度优化的需要，提供了N种优化选项用来对编译时间、目标文件长度和执行效率这个三维模型进行了取舍和平衡，默认提供了4种级别的优化供用户选择，降低使用难度。
* -O0：默认编译选项，不做任何优化；
* -O1：部分编译优化，减小生成代码的尺寸，不执行占用大量编译时间的优化；
* -O2：推荐编译选顶，进行更多优化，但是不会进行循环展开和函数内联；
* -O3：最高级别优化，会引入编译器自动向量化优化，但可能会产生一些问题；



#### 流水线优化



### 芯片配置

一般bios和OS内核配置，这里不做过多叙述。如CPU硬件预取、DDR交织、自动调频等、页表大小等。



### 代码优化

#### cache优化

##### cacheline对齐

cpu访问数据是按cacheline访问的，对于关键的热点数据，在分配内存时尽量按cacheline对齐。L1/L2 cache的cachline大小为64字节，L3 cache的cacheline字节为128字节，跨越cpu cluster的共享內存需要按L3 cacheline对齐。



##### 消除伪共享

伪共享是指多核的多个私有变量位于同一个cacheline内，由于每个核修改变量时，会将其它核的整个cacheline无效掉，这样就会造成该cacheline在不同的核频繁迁移。这种现象类似共享变量的读写，但又不是真正的共享变量，故称伪共享。

优化方案：
* OpenMP代码中使用reduction子句替代直接写入共享变量（循环过程中写入线程私有变量）
* 线程私有的变量按照cacheline大小对齐（线程栈上的变量除外）
* 使用线程私有变量（如GCC支持`_thread`、C11支持`_Thread_local`关键字）



##### 数据重排

数据重排是指将物理上不连续的热点数据变成连续的数据，使得CPU可以按cachline访问，提升cache命中率。



##### 使用软件预取

软件预取是指通过PRFM指令提前将后面要使用的数据加载到cache中，避免使用时再读取数据增加cache miss的内存访问延迟。

GCC中可以使用`__builtin_prefetch`函数，函数原型为`__builtin_prefetch(const void *addr, int rw, int locality)`，其中add为要预取的地址，rw预取addr所在cacheline接下来是要做什么操作（读还是写，取值可为0/1，默认值为0，0表示读，1表示写），locality为预取之后访问此 cacheline的频率（取值可为0/1/2/3，0表示只访问一次，该cacheline不应该驻留；3表示该条cacheline将来会被较为频繁地访问，应尽量驻留在所有level的cache中）



##### non-temporal load/store

ARMv8提供了Non-temporal的Load/Store指令，可以提高cache的利用率。对于一些数据，如果只是访问一次，无需占用cache，可以使用这个指令进行访问，从而保护cache中关键数据不被替换，比如memcpy大数据的场景下，使用该指令对于其关键业务而言，是有一定的收益的



#### 结构体优化

##### 字节对齐

首先解释一下对齐的概念。例如，总线的数据宽度为64bit（8 byte对齐），burst size=64bit，burst length=4，如果要往地址0xf0002000写入32byte，只要一次传输就可以完成。如果要往0xf0002001写入32byte，就要拆分成2次非对齐传输了，显然传输效率比一次传输要差。



字节对齐
* `__attribute__((packed))`
* `__attribute__((aligned(4)))`



保持结构体字节对齐主要是使得cpu从内存读取数据的延迟降低。



##### 调整成员顺序

有时对于一个较大的结构体，如果某两个结构体成员间隔较大，跨越了2个cacheline，刚好某个热点函数需要频繁访问这两个成员，可能引起较大的cache miss（一个成员的修改可能导致另一个成员所在的cacheline被替换出去）。可以将两个成员放入一个cacheline內，提升cache的利用率。



#### 循环优化

##### 循环展开

##### 循环融合

##### 循环分离

##### 循环置换

##### 循环平铺



#### 分支优化

##### 分支预测优化

* 充分利用likely()和unlikely()等预编译指令增加条件分支预测的准确性，缩短指令运行路径
* 避免将判断放在循环内；
* 拆分循环，将循环内的多条件分支运行拆分成多个循环，避免判断（例如奇偶拆分）；
*   合并条件，多个条件合并成一个分支预测；
*   使用三目条件运算符，编译器将优化会条件赋值语句，可以提开性能；
* 使用查表的方式减少分支；



##### 优化逻辑表达式



##### 多分支使用swtich替换if-else

多分支条件语句一般采用switch语句，这样的程序无论从清晰性和效率上都比原来的程序要好。因为switch-case语句实际上会生成一个连续的查找表，在查找对应case，均只需要一次比较，而if-else需要每个条件都计算一遍。实际编程中，当分支比较少时，使用if-else即可，当分支比较多，使用switch-case。需要注意的是，由于switch-case的查找表大小为case最大值与最小值之间的间距，如果case条件值跳跃性太大，编译器会将switch-case退化成if-else。所以switch-case通通常用于多个连续的enum类型的成员的比较。



#### 函数优化

##### 函数参数传递

函数参数优先通过寄存器传递，超过8个会通过栈传递。如果参数是大结构体或者类时，会有调用时的复制开销和返回时的销毁开销。改成指针传递则只需要传递一个指针即可。开销较少。



##### 内联函数

内联函数是典型的空间换时间的优化方法。
* 优点：
    * 消除函数调用的开销。
    * 如果函数调用在循环体内，则编译器很难进行向量化。此时循环体内调用的函数如果采用内联形式的话，则编译器可识别优化
* 缺点：
    * 如果内联后的函数校长，会增加寄存器压力
    * 如果函数内有分支，内联后会对指令流水线产生不利影响



#### 指令优化

##### 指令向量化

编译选项中填写-free-vectorize，或编译优化设置为-O3（O3会做更激进的循环展开，函数内联，更耗时的指针别名分析，更复杂的指令模式匹配（比如指令的向量化），更耗时的指令调度，寄存器分配，会增加代码体积，慎用）

手工对热点函数使用向量化指令改写



##### 减少高开销的指令

除法指令开销都是比较高的，程序中尽量通过调整算法来减少这类指令，使用位移、加法、乘法等指令来实现。



##### 指令重排序

指令重排序有两个层面，一个是CPU硬件上为了提升性能，会将代码中的指令顺序乱序执行，以最大程度利用硬件的运算单元，提升执行效率，并保证最终结果与代码指令顺序一致；另一个层面是编译器对指令顺序进行重排，减少数据依赖。在手写汇编代码时，也需要尽量调整指令的顺序，提升性能。



##### 指令替换

CPU有多条流水线（pipeline），不同的流水线会执行不同类型指令，如果在一个指令序列中，两条有数据依赖的指令占用了同一条流水，可能导致流水线冲突，使得性能降低。



#### 减少不必要的barrier

现代CPU为了提开流水线的执行效率，一般都实现了乱序执行的功能，意味着代码的指令顺序与指令实际执行顺序可能不一样，特别是没有寄存器依赖的两条指令，执行顺序无法确定。但有些场景，我们希望这两条指令是保序的，比如往某个内存地址写入一个值后，需要等到写入完成后（写入内存是需要时间的），再往某个外设寄存器中写入数据，因为这个寄存器地址与内存地址没有数据依赖，CPU无法保证执行顺序，所以提供了 barrie指令供程序员手动进行保序。



ARMv8提供3条Barrier指令：DMB、DSB、ISB。
* DME：数据存储器隔离。DMB 指令保证：仅当所有在它前面的memory访问操作都执行完（不对非memory访问操作阻基），才执行在它后面的指令。
* DSB：数据同步隔离。比 DMB严格：仅当所有在它前面的memory访方问、device访问、cache维护等操作都执行完毕后，才执行在它后面的指令。
* ISB：指令同步隔离，会清空流水线，比DMB、DSB均要严格。



DMB、DSB、ISB执行代价依次递增，从性能角度考虑，能不用barrier的地方尽量不用，能用DMB的，不要用DSB/ISB。

另外，要注意的是ARMv8增加了Load acquire/Store release指令，隐含了barrier操作，具体参考“锁优化”章节。



#### 访存优化

##### 减少不必要的内存读写和分配

临时变量可以存到寄存器中，中间不需要保存到栈中，计算结束直接返回，减少不必要的内存读写。

内存分配是一项开销比较大的操作，对于频繁使用的内存，可以考虑在初始化时创建内存池，后续直接从内存池获取内存块。特别注意避免在循环中不必要的分配内存



##### 不要频繁使用指针获取数据，优先局部栈变量



##### 合理使用全局变量

在编程中使用全局变量的，编译器优化后进入某函数栈，加载至对应代码块时編译器不会为全局变量分配寄存器；而使用局部变量可以在编译器优化时编译出寄存器级别操作，减少多余的Load操作。



优化方法：

* 非必要场景，建议使用局部变量；
* 若涉及全局变量需要被多个函数读取，而不是修改的场景，可以将全局变量作为形参的形式传入，并添加const关键词，避免在函数调用过程中全局变量被修改；
* 若全局变量要被别的模块调用时，建议get/set形式封装，避免直接使用全局变量



#### 多核优化

##### 锁优化

* LL/SC（Load-link/Store-condition）原子指令需要把共享变量先load到本核所在的L1 cache中进行修改，在锁竞争少的情况下性能较好，但在锁竞争激烈时会导致系统性能下降严重。ARMv8.1规范中引入了新的原子操作指令扩展LSE （Large SystemExtensions），将计算操作放到L3 cache去做，增大数据共享范围，减少cache一致性耗时，在锁竞争激烈时可以提升锁的性能。
    * LL/SC指令（Idaxr&stlxr）
    * LSE指令（ldaddal）
* 在多核、原子锁争抢严重的情况下，建议在GCC编译选项中添加LSE相关选顶，减缓锁竞争。
    * -march=armv8-a+lse
    * -march=armv8.1-a
    * -march=armv8.2-a
* 由于ARMv8提供Load acquire/Store release指令LDAR/STLR，隐含了barrier操作，在实现原子操作时，要避免不必要的barrier



##### 减少跨numa访问

乐高架构，每个处理器Socket内部拥有两个NUMA Node。

线程/进程实际运行所在的物理核与内存NUMA Node位置关系，会带来访存路径时延的差异，本地访问性能最佳，本Socket内跨一次NUMA次之，跨Socket访方问性能最不理想。



优化方案

* 避免线程在运行过程中迁移：使用OpenMP时，通过配置环境变量OMP_PROC_BIND=tue及OMP_PLACES指定线程要绑定的CPU核
* 使用numactl、taskset、cgroup/cpuset工具绑定进程/线程的位置关系
    * `numactl -H`：查看当前嚴务器的NUMAN置。
    * `numactl -C 0-7 test`：将应用程序test绑定到0-7核运行。
    * `numastat`：查看当前的NUMA运行状态。



#### 充分利用语言特性

* c++移动语义和完美转发
* 使用引用或指针传递函数参数
* 使用constexpr
* 使用c99复合字面量对单一结构体清零